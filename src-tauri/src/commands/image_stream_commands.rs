//! å›¾ç‰‡æµå¼åŠ è½½å‘½ä»¤
//!
//! ä½¿ç”¨ Tauri Channel å®ç°å¤§å›¾ç‰‡çš„æµå¼ä¼ è¾“
//! è¾¹è§£å‹è¾¹ä¼ è¾“ï¼ŒçœŸæ­£çš„æµå¼è¯»å–

use base64::{engine::general_purpose::STANDARD, Engine};
use log::{info, warn};
use serde::{Deserialize, Serialize};
use std::io::Read;
use std::path::PathBuf;
use std::sync::Arc;
use tauri::{ipc::Channel, State};
use tokio::sync::mpsc;

use crate::commands::fs_commands::FsState;
use crate::core::archive::ArchiveFormat;

/// æµå¼ä¼ è¾“å—å¤§å° (64KBï¼Œæ›´å°çš„å—å‡å°‘é¦–å­—èŠ‚å»¶è¿Ÿ)
const STREAM_CHUNK_SIZE: usize = 64 * 1024;

/// å›¾ç‰‡æµè¾“å‡ºç±»å‹
#[derive(Debug, Clone, Serialize, Deserialize)]
#[serde(tag = "type", rename_all = "camelCase")]
pub enum ImageStreamOutput {
    /// æ•°æ®å—
    Chunk {
        /// å—ç´¢å¼•
        index: usize,
        /// Base64 ç¼–ç çš„æ•°æ®
        data: String,
        /// å—å¤§å°ï¼ˆå­—èŠ‚ï¼‰
        size: usize,
        /// é¢„ä¼°æ€»å¤§å°ï¼ˆå¦‚æœå·²çŸ¥ï¼‰
        estimated_total: Option<usize>,
    },
    /// ä¼ è¾“å®Œæˆ
    Complete {
        /// æ€»å­—èŠ‚æ•°
        total_bytes: usize,
        /// æ€»å—æ•°
        total_chunks: usize,
        /// è€—æ—¶ï¼ˆæ¯«ç§’ï¼‰
        elapsed_ms: u64,
    },
    /// é”™è¯¯
    Error {
        message: String,
    },
}

/// æµå¼åŠ è½½å‹ç¼©åŒ…å›¾ç‰‡ï¼ˆçœŸæ­£çš„æµå¼è¯»å–ï¼‰
///
/// è¾¹è§£å‹è¾¹é€šè¿‡ Channel æ¨é€æ•°æ®å—
/// å‰ç«¯å¯ä»¥è¾¹æ¥æ”¶è¾¹è§£ç ï¼Œå®ç°æ¸è¿›å¼åŠ è½½
#[tauri::command]
pub async fn stream_image_from_archive(
    archive_path: String,
    file_path: String,
    channel: Channel<ImageStreamOutput>,
    state: State<'_, FsState>,
) -> Result<(), String> {
    let start = std::time::Instant::now();
    let archive_path_buf = PathBuf::from(&archive_path);
    let inner_path = file_path.clone();

    info!(
        "ğŸ“¥ [ImageStream] å¼€å§‹æµå¼åŠ è½½: archive={} inner={}",
        archive_path, file_path
    );

    // æ£€æµ‹å‹ç¼©åŒ…æ ¼å¼
    let format = ArchiveFormat::from_extension(&archive_path_buf);
    
    // åªæœ‰ ZIP æ”¯æŒçœŸæ­£çš„æµå¼è¯»å–
    // RAR å’Œ 7z éœ€è¦å®Œæ•´è§£å‹åå†åˆ†å—å‘é€
    if format != ArchiveFormat::Zip {
        return stream_non_zip_archive(
            archive_path_buf,
            inner_path,
            channel,
            state,
            start,
        ).await;
    }

    // ZIP: çœŸæ­£çš„æµå¼è¯»å–
    let archive_manager = Arc::clone(&state.archive_manager);
    
    // åˆ›å»ºå†…éƒ¨ channel ç”¨äºä»é˜»å¡çº¿ç¨‹å‘é€æ•°æ®
    let (tx, mut rx) = mpsc::channel::<ImageStreamOutput>(16);
    
    // åœ¨é˜»å¡çº¿ç¨‹ä¸­æ‰§è¡Œæµå¼è§£å‹
    let archive_path_clone = archive_path_buf.clone();
    let inner_path_clone = inner_path.clone();
    tokio::task::spawn_blocking(move || {
        let result = stream_zip_file(
            &archive_manager,
            &archive_path_clone,
            &inner_path_clone,
            tx.clone(),
            start,
        );
        
        if let Err(e) = result {
            let _ = tx.blocking_send(ImageStreamOutput::Error {
                message: e,
            });
        }
    });

    // è½¬å‘æ•°æ®åˆ° Tauri Channel
    while let Some(output) = rx.recv().await {
        let is_done = matches!(output, ImageStreamOutput::Complete { .. } | ImageStreamOutput::Error { .. });
        
        if let Err(e) = channel.send(output) {
            warn!("âš ï¸ [ImageStream] å‘é€åˆ° channel å¤±è´¥: {}", e);
            break;
        }
        
        if is_done {
            break;
        }
    }

    Ok(())
}

/// ZIP æ–‡ä»¶æµå¼è¯»å–ï¼ˆè¾¹è§£å‹è¾¹å‘é€ï¼‰
fn stream_zip_file(
    archive_manager: &Arc<std::sync::Mutex<crate::core::ArchiveManager>>,
    archive_path: &PathBuf,
    file_path: &str,
    tx: mpsc::Sender<ImageStreamOutput>,
    start: std::time::Instant,
) -> Result<(), String> {
    let manager = archive_manager
        .lock()
        .unwrap_or_else(|e| e.into_inner());
    
    // è·å–ç¼“å­˜çš„å‹ç¼©åŒ…å®ä¾‹
    let cached_archive = manager.get_cached_archive(archive_path)?;
    let mut archive = cached_archive.lock().unwrap();
    
    // è·å–æ–‡ä»¶
    let mut zip_file = archive
        .by_name(file_path)
        .map_err(|e| format!("åœ¨å‹ç¼©åŒ…ä¸­æ‰¾ä¸åˆ°æ–‡ä»¶: {}", e))?;
    
    // è·å–é¢„ä¼°å¤§å°ï¼ˆè§£å‹åå¤§å°ï¼‰
    let estimated_total = Some(zip_file.size() as usize);
    
    info!(
        "ğŸ“¦ [ImageStream] ZIP æµå¼è¯»å–å¼€å§‹: file={} estimated_size={:?}",
        file_path, estimated_total
    );
    
    // æµå¼è¯»å–å¹¶å‘é€
    let mut buffer = vec![0u8; STREAM_CHUNK_SIZE];
    let mut chunk_index = 0;
    let mut total_bytes = 0;
    
    loop {
        let bytes_read = zip_file
            .read(&mut buffer)
            .map_err(|e| format!("è¯»å–æ–‡ä»¶å¤±è´¥: {}", e))?;
        
        if bytes_read == 0 {
            break; // EOF
        }
        
        total_bytes += bytes_read;
        
        // Base64 ç¼–ç å¹¶å‘é€
        let encoded = STANDARD.encode(&buffer[..bytes_read]);
        let output = ImageStreamOutput::Chunk {
            index: chunk_index,
            data: encoded,
            size: bytes_read,
            estimated_total,
        };
        
        if tx.blocking_send(output).is_err() {
            warn!("âš ï¸ [ImageStream] æ¥æ”¶ç«¯å·²å…³é—­");
            return Ok(());
        }
        
        chunk_index += 1;
    }
    
    // å‘é€å®Œæˆä¿¡å·
    let elapsed = start.elapsed();
    let _ = tx.blocking_send(ImageStreamOutput::Complete {
        total_bytes,
        total_chunks: chunk_index,
        elapsed_ms: elapsed.as_millis() as u64,
    });
    
    info!(
        "ğŸ“¤ [ImageStream] ZIP æµå¼è¯»å–å®Œæˆ: bytes={} chunks={} elapsed={}ms",
        total_bytes, chunk_index, elapsed.as_millis()
    );
    
    Ok(())
}

/// é ZIP æ ¼å¼çš„æµå¼ä¼ è¾“ï¼ˆå…ˆè§£å‹å†åˆ†å—å‘é€ï¼‰
async fn stream_non_zip_archive(
    archive_path: PathBuf,
    file_path: String,
    channel: Channel<ImageStreamOutput>,
    state: State<'_, FsState>,
    start: std::time::Instant,
) -> Result<(), String> {
    let archive_manager = Arc::clone(&state.archive_manager);
    
    // åœ¨é˜»å¡çº¿ç¨‹ä¸­å®Œæ•´è§£å‹
    let result = tokio::task::spawn_blocking(move || {
        let manager = archive_manager
            .lock()
            .unwrap_or_else(|e| e.into_inner());
        manager.load_image_from_archive_binary(&archive_path, &file_path)
    })
    .await
    .map_err(|e| format!("spawn_blocking error: {}", e))?;
    
    match result {
        Ok(bytes) => {
            let total_bytes = bytes.len();
            let chunks: Vec<&[u8]> = bytes.chunks(STREAM_CHUNK_SIZE).collect();
            let total_chunks = chunks.len();
            
            for (i, chunk) in chunks.iter().enumerate() {
                let encoded = STANDARD.encode(chunk);
                channel
                    .send(ImageStreamOutput::Chunk {
                        index: i,
                        data: encoded,
                        size: chunk.len(),
                        estimated_total: Some(total_bytes),
                    })
                    .map_err(|e| format!("å‘é€å— {} å¤±è´¥: {}", i, e))?;
            }
            
            let elapsed = start.elapsed();
            channel
                .send(ImageStreamOutput::Complete {
                    total_bytes,
                    total_chunks,
                    elapsed_ms: elapsed.as_millis() as u64,
                })
                .map_err(|e| format!("å‘é€å®Œæˆä¿¡å·å¤±è´¥: {}", e))?;
            
            Ok(())
        }
        Err(err) => {
            channel
                .send(ImageStreamOutput::Error {
                    message: err.clone(),
                })
                .ok();
            Err(err)
        }
    }
}

/// æ£€æŸ¥æ˜¯å¦åº”è¯¥ä½¿ç”¨æµå¼ä¼ è¾“
#[tauri::command]
pub fn should_use_stream(size: usize) -> bool {
    size > STREAM_CHUNK_SIZE * 2 // è¶…è¿‡ 128KB ä½¿ç”¨æµå¼
}
