//! Thumbnail Service V3
//! ç¼©ç•¥å›¾æœåŠ¡ V3 - å¤åˆ» NeeView æ¶æ„
//!
//! æ ¸å¿ƒç‰¹ç‚¹ï¼š
//! 1. åç«¯ä¸ºä¸»ï¼Œå‰ç«¯åªéœ€é€šçŸ¥å¯è§åŒºåŸŸ + æ¥æ”¶ blob
//! 2. ä¸é˜»å¡å‰ç«¯æ–‡ä»¶å¤¹æµè§ˆ
//! 3. LRU å†…å­˜ç¼“å­˜ + SQLite æ•°æ®åº“ç¼“å­˜
//! 4. å¤šçº¿ç¨‹å·¥ä½œæ± å¹¶è¡Œç”Ÿæˆ

// å­æ¨¡å—å£°æ˜
pub mod cache;
pub mod config;
pub mod db_index;
pub mod generators;
pub mod queue;
pub mod types;
pub mod worker;

// é‡å¯¼å‡ºå…¬å…± API
pub use config::ThumbnailServiceConfig;
pub use types::{
    detect_file_type, is_archive_file, is_likely_folder, CacheStats, ThumbnailBatchReadyPayload,
    TaskLane, ThumbnailFileType, ThumbnailReadyPayload,
};

// å†…éƒ¨ä½¿ç”¨
use crate::core::thumbnail_db::ThumbnailDb;
use crate::core::thumbnail_generator::ThumbnailGenerator;
use crate::core::request_dedup::RequestDeduplicator;
use lru::LruCache;
use std::collections::{HashMap, HashSet};
use std::num::NonZeroUsize;
use std::sync::atomic::{AtomicBool, AtomicU64, AtomicUsize, Ordering};
use std::sync::{Arc, Condvar, Mutex, RwLock};
use std::thread::JoinHandle;
use std::time::Instant;
use tauri::{AppHandle, Emitter};

use types::GenerateTask;

// ç®€åŒ–çš„æ—¥å¿—å®ï¼ˆæ›¿ä»£ tracingï¼‰
macro_rules! log_info {
    ($($arg:tt)*) => {
        println!("[INFO] {}", format!($($arg)*));
    };
}

macro_rules! log_debug {
    ($($arg:tt)*) => {
        if cfg!(debug_assertions) {
            println!("[DEBUG] {}", format!($($arg)*));
        }
    };
}

// å¯¼å‡ºå®ä¾›å­æ¨¡å—ä½¿ç”¨
pub(crate) use log_debug;
pub(crate) use log_info;

/// ç¼©ç•¥å›¾æœåŠ¡ V3
pub struct ThumbnailServiceV3 {
    /// é…ç½®
    config: ThumbnailServiceConfig,
    /// å†…å­˜ç¼“å­˜ (LRU)
    memory_cache: Arc<RwLock<LruCache<String, Vec<u8>>>>,
    /// å†…å­˜ç¼“å­˜å¤§å°ï¼ˆå­—èŠ‚ï¼‰
    memory_cache_bytes: Arc<AtomicUsize>,
    /// æ•°æ®åº“
    db: Arc<ThumbnailDb>,
    /// ç¼©ç•¥å›¾ç”Ÿæˆå™¨
    generator: Arc<ThumbnailGenerator>,
    /// ç”Ÿæˆä»»åŠ¡é˜Ÿåˆ—
    task_queue: Arc<(Mutex<queue::TaskQueueState>, Condvar)>,
    /// å½“å‰ç›®å½•
    current_dir: Arc<RwLock<String>>,
    /// è¯·æ±‚åˆ†ä»£å·ï¼ˆç›®å½•åˆ‡æ¢æ—¶é€’å¢ï¼Œæ—§ä»»åŠ¡è‡ªåŠ¨å¤±æ•ˆï¼‰
    request_epoch: Arc<AtomicU64>,
    /// è°ƒåº¦æ€»å¼€å…³ï¼ˆpause/resumeï¼‰
    scheduler_paused: Arc<AtomicBool>,
    /// æ˜¯å¦æ­£åœ¨è¿è¡Œ
    running: Arc<AtomicBool>,
    /// æ´»è·ƒå·¥ä½œçº¿ç¨‹æ•°
    active_workers: Arc<AtomicUsize>,
    /// å„è½¦é“å¾…å¤„ç†é˜Ÿåˆ—è®¡æ•°ï¼ˆO(1) backlogï¼‰
    queued_visible: Arc<AtomicUsize>,
    queued_prefetch: Arc<AtomicUsize>,
    queued_background: Arc<AtomicUsize>,
    /// å„è½¦é“å·²å¤„ç†ä»»åŠ¡è®¡æ•°
    processed_visible: Arc<AtomicUsize>,
    processed_prefetch: Arc<AtomicUsize>,
    processed_background: Arc<AtomicUsize>,
    /// è§£ç /ç¼–ç é˜¶æ®µç­‰å¾…ç»Ÿè®¡
    decode_wait_count: Arc<AtomicUsize>,
    decode_wait_ms: Arc<AtomicU64>,
    scale_wait_count: Arc<AtomicUsize>,
    scale_wait_ms: Arc<AtomicU64>,
    encode_wait_count: Arc<AtomicUsize>,
    encode_wait_ms: Arc<AtomicU64>,
    window_pruned_tasks: Arc<AtomicUsize>,
    cache_decay_evicted_entries: Arc<AtomicUsize>,
    cache_decay_evicted_bytes: Arc<AtomicU64>,
    io_prefetch_runs: Arc<AtomicUsize>,
    io_prefetch_files: Arc<AtomicUsize>,
    io_prefetch_ms: Arc<AtomicU64>,
    db_read_window: Arc<AtomicUsize>,
    db_read_last_ms: Arc<AtomicU64>,
    db_write_window: Arc<AtomicUsize>,
    db_write_last_ms: Arc<AtomicU64>,
    db_write_last_items: Arc<AtomicUsize>,
    /// å·¥ä½œçº¿ç¨‹å¥æŸ„
    workers: Arc<Mutex<Vec<JoinHandle<()>>>>,
    /// æ•°æ®åº“ç´¢å¼• (å·²æœ‰ç¼©ç•¥å›¾çš„è·¯å¾„é›†åˆ)
    db_index: Arc<RwLock<HashSet<String>>>,
    /// æ–‡ä»¶å¤¹æ•°æ®åº“ç´¢å¼•
    folder_db_index: Arc<RwLock<HashSet<String>>>,
    /// å¤±è´¥è®°å½•ç´¢å¼•
    failed_index: Arc<RwLock<HashSet<String>>>,
    /// ä¿å­˜é˜Ÿåˆ—ï¼ˆå»¶è¿Ÿæ‰¹é‡ä¿å­˜åˆ°æ•°æ®åº“ï¼‰
    save_queue: Arc<Mutex<HashMap<String, (Vec<u8>, i64, i32, Instant)>>>,
    /// æœ€åä¸€æ¬¡ä¿å­˜é˜Ÿåˆ—åˆ·æ–°æ—¶é—´
    last_flush: Arc<Mutex<Instant>>,
    /// æ‰¹é‡ä¿å­˜é˜ˆå€¼
    batch_save_threshold: usize,
    /// è¯·æ±‚å»é‡å™¨
    request_deduplicator: Arc<RequestDeduplicator>,
}

impl ThumbnailServiceV3 {
    /// åˆ›å»ºæ–°çš„ç¼©ç•¥å›¾æœåŠ¡
    pub fn new(
        db: Arc<ThumbnailDb>,
        generator: Arc<ThumbnailGenerator>,
        config: ThumbnailServiceConfig,
    ) -> Self {
        let cache_size =
            NonZeroUsize::new(config.memory_cache_size).unwrap_or(NonZeroUsize::new(1024).unwrap());
        let db_read_window_init = config.db_read_batch_min.max(1);
        let db_write_window_init = config.db_write_batch_min.max(1);

        // ä»æ•°æ®åº“åŠ è½½ç´¢å¼•
        let (db_index, folder_db_index, failed_index) = db_index::load_indices_from_db(&db);
        log_info!(
            "ğŸ“Š æ•°æ®åº“ç´¢å¼•åŠ è½½å®Œæˆ: {} ä¸ªç¼©ç•¥å›¾, {} ä¸ªæ–‡ä»¶å¤¹, {} ä¸ªå¤±è´¥è®°å½•",
            db_index.len(),
            folder_db_index.len(),
            failed_index.len()
        );

        Self {
            config,
            memory_cache: Arc::new(RwLock::new(LruCache::new(cache_size))),
            memory_cache_bytes: Arc::new(AtomicUsize::new(0)),
            db,
            generator,
            task_queue: Arc::new((Mutex::new(queue::TaskQueueState::default()), Condvar::new())),
            current_dir: Arc::new(RwLock::new(String::new())),
            request_epoch: Arc::new(AtomicU64::new(1)),
            scheduler_paused: Arc::new(AtomicBool::new(false)),
            running: Arc::new(AtomicBool::new(false)),
            active_workers: Arc::new(AtomicUsize::new(0)),
            queued_visible: Arc::new(AtomicUsize::new(0)),
            queued_prefetch: Arc::new(AtomicUsize::new(0)),
            queued_background: Arc::new(AtomicUsize::new(0)),
            processed_visible: Arc::new(AtomicUsize::new(0)),
            processed_prefetch: Arc::new(AtomicUsize::new(0)),
            processed_background: Arc::new(AtomicUsize::new(0)),
            decode_wait_count: Arc::new(AtomicUsize::new(0)),
            decode_wait_ms: Arc::new(AtomicU64::new(0)),
            scale_wait_count: Arc::new(AtomicUsize::new(0)),
            scale_wait_ms: Arc::new(AtomicU64::new(0)),
            encode_wait_count: Arc::new(AtomicUsize::new(0)),
            encode_wait_ms: Arc::new(AtomicU64::new(0)),
            window_pruned_tasks: Arc::new(AtomicUsize::new(0)),
            cache_decay_evicted_entries: Arc::new(AtomicUsize::new(0)),
            cache_decay_evicted_bytes: Arc::new(AtomicU64::new(0)),
            io_prefetch_runs: Arc::new(AtomicUsize::new(0)),
            io_prefetch_files: Arc::new(AtomicUsize::new(0)),
            io_prefetch_ms: Arc::new(AtomicU64::new(0)),
            db_read_window: Arc::new(AtomicUsize::new(db_read_window_init)),
            db_read_last_ms: Arc::new(AtomicU64::new(0)),
            db_write_window: Arc::new(AtomicUsize::new(db_write_window_init)),
            db_write_last_ms: Arc::new(AtomicU64::new(0)),
            db_write_last_items: Arc::new(AtomicUsize::new(0)),
            workers: Arc::new(Mutex::new(Vec::new())),
            db_index: Arc::new(RwLock::new(db_index)),
            folder_db_index: Arc::new(RwLock::new(folder_db_index)),
            failed_index: Arc::new(RwLock::new(failed_index)),
            save_queue: Arc::new(Mutex::new(HashMap::new())),
            last_flush: Arc::new(Mutex::new(Instant::now())),
            batch_save_threshold: 50,
            request_deduplicator: Arc::new(RequestDeduplicator::new()),
        }
    }

    /// å¯åŠ¨å·¥ä½œçº¿ç¨‹
    pub fn start(&self, app: AppHandle) {
        if self.running.swap(true, Ordering::SeqCst) {
            return; // å·²ç»åœ¨è¿è¡Œ
        }

        let mut workers_guard = self.workers.lock().unwrap();

        // å¯åŠ¨å·¥ä½œçº¿ç¨‹
        let worker_handles = worker::start_workers(
            &self.config,
            Arc::clone(&self.running),
            Arc::clone(&self.task_queue),
            Arc::clone(&self.current_dir),
            Arc::clone(&self.request_epoch),
            Arc::clone(&self.scheduler_paused),
            Arc::clone(&self.active_workers),
            Arc::clone(&self.queued_visible),
            Arc::clone(&self.queued_prefetch),
            Arc::clone(&self.queued_background),
            Arc::clone(&self.processed_visible),
            Arc::clone(&self.processed_prefetch),
            Arc::clone(&self.processed_background),
            Arc::clone(&self.decode_wait_count),
            Arc::clone(&self.decode_wait_ms),
            Arc::clone(&self.scale_wait_count),
            Arc::clone(&self.scale_wait_ms),
            Arc::clone(&self.encode_wait_count),
            Arc::clone(&self.encode_wait_ms),
            Arc::clone(&self.memory_cache),
            Arc::clone(&self.memory_cache_bytes),
            Arc::clone(&self.db),
            Arc::clone(&self.generator),
            Arc::clone(&self.db_index),
            Arc::clone(&self.folder_db_index),
            Arc::clone(&self.failed_index),
            Arc::clone(&self.save_queue),
            Arc::clone(&self.request_deduplicator),
            app,
        );

        for handle in worker_handles {
            workers_guard.push(handle);
        }

        // å¯åŠ¨ä¿å­˜é˜Ÿåˆ—åˆ·æ–°çº¿ç¨‹
        let flush_handle = worker::start_flush_thread(
            Arc::clone(&self.running),
            Arc::clone(&self.save_queue),
            Arc::clone(&self.db),
            self.config.db_save_delay_ms,
            self.batch_save_threshold,
            self.config.db_write_batch_min,
            self.config.db_write_batch_max,
            self.config.db_batch_target_ms,
            Arc::clone(&self.db_write_window),
            Arc::clone(&self.db_write_last_ms),
            Arc::clone(&self.db_write_last_items),
        );
        workers_guard.push(flush_handle);

        log_info!(
            "âœ… ThumbnailServiceV3 started with {} workers + 1 flush thread",
            self.config.worker_threads
        );
    }

    /// åœæ­¢å·¥ä½œçº¿ç¨‹
    pub fn stop(&self) {
        self.running.store(false, Ordering::SeqCst);
        self.task_queue.1.notify_all();
        let mut workers = self.workers.lock().unwrap();
        for handle in workers.drain(..) {
            let _ = handle.join();
        }
        log_info!("ğŸ›‘ ThumbnailServiceV3 stopped");
    }
}

impl ThumbnailServiceV3 {
    fn dec_counter(counter: &AtomicUsize) {
        let _ = counter.fetch_update(Ordering::Relaxed, Ordering::Relaxed, |v| {
            Some(v.saturating_sub(1))
        });
    }

    /// è¯·æ±‚å¯è§åŒºåŸŸç¼©ç•¥å›¾ï¼ˆæ ¸å¿ƒæ–¹æ³•ï¼Œä¸é˜»å¡ï¼‰
    pub fn request_visible_thumbnails(
        &self,
        app: &AppHandle,
        paths: Vec<String>,
        current_dir: String,
        center_index: Option<usize>,
        lane: TaskLane,
    ) {
        let requested_paths: HashSet<String> = paths.iter().cloned().collect();
        let center = center_index.unwrap_or(paths.len() / 2);

        // æ›´æ–°å½“å‰ç›®å½•
        {
            if let Ok(mut dir) = self.current_dir.write() {
                if *dir != current_dir {
                    let next_epoch = self.request_epoch.fetch_add(1, Ordering::AcqRel) + 1;
                    log_debug!("ğŸ“‚ ç›®å½•åˆ‡æ¢: {} -> {} (epoch={})", *dir, current_dir, next_epoch);
                    *dir = current_dir.clone();
                }
            }
        }

        if !requested_paths.is_empty() && !matches!(lane, TaskLane::Background) {
            let dropped = queue::prune_lane_directory_except(
                &self.task_queue,
                lane,
                &current_dir,
                &requested_paths,
            );
            let dropped_len = dropped.len();
            for task in dropped {
                match task.lane {
                    TaskLane::Visible => Self::dec_counter(&self.queued_visible),
                    TaskLane::Prefetch => Self::dec_counter(&self.queued_prefetch),
                    TaskLane::Background => Self::dec_counter(&self.queued_background),
                }
                self.request_deduplicator
                    .release_with_id(&task.dedup_key, task.dedup_request_id);
            }
            self.window_pruned_tasks
                .fetch_add(dropped_len, Ordering::Relaxed);
        }

        // æ‰¹é‡åˆ†ç±»è·¯å¾„
        let mut cached_paths: Vec<String> = Vec::new();
        let mut db_paths: Vec<String> = Vec::new();
        let mut generate_paths: Vec<(String, ThumbnailFileType, usize, u64)> = Vec::new();

        // æ‰¹é‡é¢„è·å–æ‰€æœ‰é”ï¼šæ•´ä¸ªå¾ªç¯å…±äº«ï¼Œæ¶ˆé™¤ 2N æ¬¡ lock/unlockï¼ˆN = å¯è§è·¯å¾„æ•°ï¼‰
        // è¯»é”å¹¶å‘å®‰å…¨ï¼šworker å†™é”åœ¨ä»»åŠ¡å®Œæˆæ—¶çŸ­æš‚è·å–ï¼Œä¸ä¼šæ­»é”
        let mem_guard = self.memory_cache.read().ok();
        let sq_guard = self.save_queue.lock().ok();
        let db_guard = self.db_index.read().ok();
        let folder_guard = self.folder_db_index.read().ok();
        let failed_guard = self.failed_index.read().ok();

        // åˆ†ç±»æ¯ä¸ªè·¯å¾„
        for (priority, path) in paths.into_iter().enumerate() {
            // æ£€æŸ¥å†…å­˜ç¼“å­˜ï¼ˆä½¿ç”¨é¢„è·å–çš„é”ï¼Œé¿å…æ¯æ¬¡å¾ªç¯é‡æ–°è·å–ï¼‰
            let in_mem = mem_guard
                .as_ref()
                .map(|c| c.peek(path.as_str()).is_some())
                .unwrap_or(false)
                || sq_guard
                    .as_ref()
                    .map(|q| q.contains_key(path.as_str()))
                    .unwrap_or(false);
            if in_mem {
                cached_paths.push(path);
                continue;
            }
            // æ£€æŸ¥å¤±è´¥ç´¢å¼•ï¼ˆ&str æŸ¥è¯¢ï¼ŒHashSet<String> æ”¯æŒ Borrow<str>ï¼‰
            if let Some(ref failed) = failed_guard {
                if failed.contains(path.as_str()) {
                    continue;
                }
            }
            // æ£€æŸ¥æ•°æ®åº“ç´¢å¼•
            let in_db = db_guard
                .as_ref()
                .map(|i| i.contains(path.as_str()))
                .unwrap_or(false);
            let in_folder = folder_guard
                .as_ref()
                .map(|i| i.contains(path.as_str()))
                .unwrap_or(false);

            if in_db || in_folder {
                db_paths.push(path);
            } else {
                let file_type = detect_file_type(path.as_str());
                if let Some(request_id) = self.request_deduplicator.try_acquire(path.as_str()) {
                    generate_paths.push((path, file_type, priority, request_id));
                }
            }
        }

        // æ˜¾å¼é‡Šæ”¾æ‰€æœ‰é”ï¼Œé¿å…åç»­ load_from_db_async / enqueue_tasks æ­»é”
        drop(mem_guard);
        drop(sq_guard);
        drop(db_guard);
        drop(folder_guard);
        drop(failed_guard);

        // 1. ç«‹å³æ‰¹é‡å‘é€å†…å­˜ç¼“å­˜å‘½ä¸­çš„ï¼ˆä»…å‘ pathï¼Œå‰ç«¯é€šè¿‡åè®® URL å–æ•°æ®ï¼‰
        if !cached_paths.is_empty() {
            let payload = ThumbnailBatchReadyPayload {
                items: cached_paths.into_iter().map(|path| ThumbnailReadyPayload { path }).collect(),
            };
            let _ = app.emit("thumbnail-batch-ready", payload);
        }

        // 2. æ‰¹é‡ä»æ•°æ®åº“åŠ è½½
        if !db_paths.is_empty() {
            self.load_from_db_async(app.clone(), db_paths);
        }

        // 3. å…¥é˜Ÿç”Ÿæˆä»»åŠ¡
        if !generate_paths.is_empty() {
            let epoch = self.request_epoch.load(Ordering::Acquire);
            queue::enqueue_tasks(
                &self.task_queue,
                generate_paths,
                &current_dir,
                center,
                epoch,
                lane,
                &self.queued_visible,
                &self.queued_prefetch,
                &self.queued_background,
            );
        }

        // å†…å­˜å‹åŠ›æ£€æŸ¥
        static REQ_COUNT: std::sync::atomic::AtomicUsize = std::sync::atomic::AtomicUsize::new(0);
        if REQ_COUNT.fetch_add(1, Ordering::Relaxed) % 100 == 0 {
            self.two_phase_cache_cleanup(256 * 1024 * 1024);
        }
    }

    /// å¼‚æ­¥ä»æ•°æ®åº“åŠ è½½ç¼©ç•¥å›¾
    fn load_from_db_async(&self, app: AppHandle, db_paths: Vec<String>) {
        let db = Arc::clone(&self.db);
        let memory_cache = Arc::clone(&self.memory_cache);
        let memory_cache_bytes = Arc::clone(&self.memory_cache_bytes);
        let db_read_window_stats = Arc::clone(&self.db_read_window);
        let db_read_last_ms_stats = Arc::clone(&self.db_read_last_ms);
        let read_min = self.config.db_read_batch_min.max(1);
        let read_max = self.config.db_read_batch_max.max(read_min);
        let target_ms = self.config.db_batch_target_ms.max(4);

        tokio::spawn(async move {
            let mut read_window = db_read_window_stats
                .load(Ordering::Relaxed)
                .clamp(read_min, read_max);

            let mut offset = 0usize;
            while offset < db_paths.len() {
                let end = (offset + read_window).min(db_paths.len());
                let chunk_started = Instant::now();
                let chunk_paths = &db_paths[offset..end];

                let mut loaded: Vec<(String, Vec<u8>)> = Vec::with_capacity(chunk_paths.len());
                for path in chunk_paths {
                    let likely_folder = is_likely_folder(path);
                    let (primary, secondary) = if likely_folder {
                        ("folder", "file")
                    } else {
                        ("file", "folder")
                    };

                    let loaded_blob = db
                        .load_thumbnail_by_key_and_category(path, primary)
                        .ok()
                        .flatten()
                        .or_else(|| {
                            db.load_thumbnail_by_key_and_category(path, secondary)
                                .ok()
                                .flatten()
                        });

                    if let Some(blob) = loaded_blob {
                        loaded.push((path.clone(), blob));
                        let _ = db.update_access_time(path);
                    }
                }

                if !loaded.is_empty() {
                    let mut payloads: Vec<ThumbnailReadyPayload> = Vec::with_capacity(loaded.len());
                    if let Ok(mut c) = memory_cache.write() {
                        for (path, blob) in loaded {
                            memory_cache_bytes.fetch_add(blob.len(), Ordering::SeqCst);
                            payloads.push(ThumbnailReadyPayload { path: path.clone() });
                            c.put(path, blob);
                        }
                    }

                    let emit_batch_size = read_window.clamp(8, 64);
                    for batch in payloads.chunks(emit_batch_size) {
                        let payload = ThumbnailBatchReadyPayload {
                            items: batch
                                .iter()
                                .map(|p| ThumbnailReadyPayload {
                                    path: p.path.clone(),
                                })
                                .collect(),
                        };
                        let _ = app.emit("thumbnail-batch-ready", payload);
                    }
                }

                let elapsed_ms = chunk_started.elapsed().as_millis() as u64;
                db_read_last_ms_stats.store(elapsed_ms, Ordering::Relaxed);

                if elapsed_ms > target_ms && read_window > read_min {
                    read_window = read_window.saturating_sub(4).max(read_min);
                } else if elapsed_ms < target_ms / 2 && chunk_paths.len() == read_window && read_window < read_max {
                    read_window = (read_window + 4).min(read_max);
                }

                db_read_window_stats.store(read_window, Ordering::Relaxed);
                offset = end;
            }
        });
    }

    /// å–æ¶ˆæŒ‡å®šç›®å½•çš„è¯·æ±‚
    pub fn cancel_requests(&self, dir: &str) {
        let removed_tasks = queue::clear_directory_tasks(&self.task_queue, dir);
        for task in removed_tasks.iter() {
            match task.lane {
                TaskLane::Visible => Self::dec_counter(&self.queued_visible),
                TaskLane::Prefetch => Self::dec_counter(&self.queued_prefetch),
                TaskLane::Background => Self::dec_counter(&self.queued_background),
            }
            self.request_deduplicator
                .release_with_id(&task.dedup_key, task.dedup_request_id);
        }
        log_debug!("ğŸš« å–æ¶ˆ {} ä¸ªä»»åŠ¡ (ç›®å½•: {})", removed_tasks.len(), dir);
    }

    /// ä»å†…å­˜ç¼“å­˜è·å–
    fn get_from_memory_cache(&self, path: &str) -> Option<Vec<u8>> {
        cache::get_from_memory_cache(&self.memory_cache, &self.save_queue, path)
    }

    /// æ£€æŸ¥å†…å­˜ç¼“å­˜æ˜¯å¦å­˜åœ¨
    fn has_in_memory_cache(&self, path: &str) -> bool {
        cache::has_in_memory_cache(&self.memory_cache, &self.save_queue, path)
    }

    /// ä»å†…å­˜ç¼“å­˜ peekï¼ˆè¯»é”ï¼Œä¸æ›´æ–° LRU é¡ºåºï¼‰â€”â€” ç”¨äºåè®®å¤„ç†å™¨
    fn peek_from_memory_cache(&self, path: &str) -> Option<Vec<u8>> {
        cache::peek_from_memory_cache(&self.memory_cache, &self.save_queue, path)
    }

    /// ä¸¤é˜¶æ®µç¼“å­˜æ¸…ç†
    pub fn two_phase_cache_cleanup(&self, max_bytes: usize) {
        let stats = cache::two_phase_cache_cleanup(
            &self.memory_cache,
            &self.memory_cache_bytes,
            &self.config,
            max_bytes,
        );
        if stats.evicted_entries > 0 {
            self.cache_decay_evicted_entries
                .fetch_add(stats.evicted_entries, Ordering::Relaxed);
            self.cache_decay_evicted_bytes
                .fetch_add(stats.evicted_bytes, Ordering::Relaxed);
        }
    }

    pub fn record_io_prefetch_stats(&self, files: usize, elapsed_ms: u64) {
        self.io_prefetch_runs.fetch_add(1, Ordering::Relaxed);
        self.io_prefetch_files.fetch_add(files, Ordering::Relaxed);
        self.io_prefetch_ms.fetch_add(elapsed_ms, Ordering::Relaxed);
    }
}

impl ThumbnailServiceV3 {
    /// å•ä¸ªç¼©ç•¥å›¾æŸ¥æ‰¾ï¼šå†…å­˜ç¼“å­˜ä¼˜å…ˆï¼Œå›è½åˆ° DBã€‚ç”±å†…å»ºåè®®çš„ /thumb/{key} ç«¯ç‚¹è°ƒç”¨ã€‚
    /// ä½¿ç”¨ peekï¼ˆè¯»é”ï¼‰è€Œé getï¼ˆå†™é”ï¼‰ï¼šå¹¶å‘ <img> è¯·æ±‚ä¸äº‰æŠ¢å†™é”
    pub fn lookup_thumbnail(&self, key: &str) -> Option<Vec<u8>> {
        // 1. å†…å­˜ç¼“å­˜ï¼ˆè¯»é” peekï¼Œä¸æ›´æ–° LRU é¡ºåºâ€”â€”é¿å… 50+ å¹¶å‘å›¾ç‰‡è¯·æ±‚äº‰æŠ¢å†™é”ï¼‰
        if let Some(blob) = self.peek_from_memory_cache(key) {
            return Some(blob);
        }
        // 2. å›è½åˆ°æ•°æ®åº“ï¼ˆæ—  syscallï¼šç”¨å¯å‘å¼ä¼˜å…ˆç±»åˆ«ï¼Œå†å›é€€å¦ä¸€ç±»åˆ«ï¼‰
        let likely_folder = is_likely_folder(key);
        let (primary, secondary) = if likely_folder {
            ("folder", "file")
        } else {
            ("file", "folder")
        };

        if let Ok(Some(blob)) = self.db.load_thumbnail_by_key_and_category(key, primary) {
            if let Ok(mut c) = self.memory_cache.write() {
                if c.peek(key).is_none() {
                    self.memory_cache_bytes.fetch_add(blob.len(), Ordering::SeqCst);
                    c.put(key.to_string(), blob.clone());
                }
            }
            return Some(blob);
        }
        if let Ok(Some(blob)) = self.db.load_thumbnail_by_key_and_category(key, secondary) {
            if let Ok(mut c) = self.memory_cache.write() {
                if c.peek(key).is_none() {
                    self.memory_cache_bytes.fetch_add(blob.len(), Ordering::SeqCst);
                    c.put(key.to_string(), blob.clone());
                }
            }
            return Some(blob);
        }
        None
    }

    /// ç›´æ¥ä»ç¼“å­˜è·å–ï¼ˆåŒæ­¥ï¼‰
    pub fn get_cached_thumbnails(&self, paths: Vec<String>) -> Vec<(String, Option<Vec<u8>>)> {
        let mut results = Vec::with_capacity(paths.len());
        let mut db_loaded_for_cache: Vec<(String, Vec<u8>)> = Vec::new();
        for path in paths {
            let blob = self.get_from_memory_cache(&path);
            if blob.is_some() {
                results.push((path, blob));
                continue;
            }
            let likely_folder = is_likely_folder(&path);
            let (primary, secondary) = if likely_folder {
                ("folder", "file")
            } else {
                ("file", "folder")
            };

            let loaded = self
                .db
                .load_thumbnail_by_key_and_category(&path, primary)
                .ok()
                .flatten()
                .or_else(|| {
                    self.db
                        .load_thumbnail_by_key_and_category(&path, secondary)
                        .ok()
                        .flatten()
                });

            if let Some(blob) = loaded {
                db_loaded_for_cache.push((path.clone(), blob.clone()));
                results.push((path, Some(blob)));
            } else {
                results.push((path, None));
            }
        }

        if !db_loaded_for_cache.is_empty() {
            if let Ok(mut c) = self.memory_cache.write() {
                for (path, blob) in db_loaded_for_cache {
                    if c.peek(path.as_str()).is_none() {
                        self.memory_cache_bytes.fetch_add(blob.len(), Ordering::SeqCst);
                        c.put(path, blob);
                    }
                }
            }
        }

        results
    }

    /// è·å–ç¼“å­˜ç»Ÿè®¡
    pub fn get_cache_stats(&self) -> CacheStats {
        let memory_count = self.memory_cache.read().map(|c| c.len()).unwrap_or(0);
        let memory_bytes = self.memory_cache_bytes.load(Ordering::SeqCst);
        let queue_visible = self.queued_visible.load(Ordering::Relaxed);
        let queue_prefetch = self.queued_prefetch.load(Ordering::Relaxed);
        let queue_background = self.queued_background.load(Ordering::Relaxed);
        let queue_length = queue_visible + queue_prefetch + queue_background;
        let active_workers = self.active_workers.load(Ordering::SeqCst);
        let processed_visible = self.processed_visible.load(Ordering::Relaxed);
        let processed_prefetch = self.processed_prefetch.load(Ordering::Relaxed);
        let processed_background = self.processed_background.load(Ordering::Relaxed);
        let decode_wait_count = self.decode_wait_count.load(Ordering::Relaxed);
        let decode_wait_ms = self.decode_wait_ms.load(Ordering::Relaxed);
        let scale_wait_count = self.scale_wait_count.load(Ordering::Relaxed);
        let scale_wait_ms = self.scale_wait_ms.load(Ordering::Relaxed);
        let encode_wait_count = self.encode_wait_count.load(Ordering::Relaxed);
        let encode_wait_ms = self.encode_wait_ms.load(Ordering::Relaxed);
        let window_pruned_tasks = self.window_pruned_tasks.load(Ordering::Relaxed);
        let cache_decay_evicted_entries = self.cache_decay_evicted_entries.load(Ordering::Relaxed);
        let cache_decay_evicted_bytes = self.cache_decay_evicted_bytes.load(Ordering::Relaxed);
        let io_prefetch_runs = self.io_prefetch_runs.load(Ordering::Relaxed);
        let io_prefetch_files = self.io_prefetch_files.load(Ordering::Relaxed);
        let io_prefetch_ms = self.io_prefetch_ms.load(Ordering::Relaxed);
        let db_read_window = self.db_read_window.load(Ordering::Relaxed);
        let db_read_last_ms = self.db_read_last_ms.load(Ordering::Relaxed);
        let db_write_window = self.db_write_window.load(Ordering::Relaxed);
        let db_write_last_ms = self.db_write_last_ms.load(Ordering::Relaxed);
        let db_write_last_items = self.db_write_last_items.load(Ordering::Relaxed);
        let (database_count, database_bytes) = self
            .db
            .get_maintenance_stats()
            .map(|(total, _, _)| (total as i64, 0i64))
            .unwrap_or((0, 0));
        CacheStats {
            memory_count,
            memory_bytes,
            database_count,
            database_bytes,
            queue_length,
            queue_visible,
            queue_prefetch,
            queue_background,
            active_workers,
            processed_visible,
            processed_prefetch,
            processed_background,
            decode_wait_count,
            decode_wait_ms,
            scale_wait_count,
            scale_wait_ms,
            encode_wait_count,
            encode_wait_ms,
            window_pruned_tasks,
            cache_decay_evicted_entries,
            cache_decay_evicted_bytes,
            io_prefetch_runs,
            io_prefetch_files,
            io_prefetch_ms,
            db_read_window,
            db_read_last_ms,
            db_write_window,
            db_write_last_ms,
            db_write_last_items,
        }
    }

    /// æ¸…é™¤ç¼“å­˜
    pub fn clear_cache(&self, scope: &str) {
        match scope {
            "memory" => {
                if let Ok(mut c) = self.memory_cache.write() {
                    c.clear();
                    self.memory_cache_bytes.store(0, Ordering::SeqCst);
                }
                log_info!("ğŸ§¹ å†…å­˜ç¼“å­˜å·²æ¸…é™¤");
            }
            "database" => {
                log_info!("ğŸ§¹ æ•°æ®åº“ç¼“å­˜æ¸…é™¤å¾…å®ç°");
            }
            _ => {
                if let Ok(mut c) = self.memory_cache.write() {
                    c.clear();
                    self.memory_cache_bytes.store(0, Ordering::SeqCst);
                }
                log_info!("ğŸ§¹ å†…å­˜ç¼“å­˜å·²æ¸…é™¤");
            }
        }
    }

    // ============== æ•°æ®åº“ç»´æŠ¤æ–¹æ³• ==============

    /// è·å–æ•°æ®åº“è¯¦ç»†ç»Ÿè®¡
    pub fn get_db_stats(&self) -> Result<(usize, usize, i64), String> {
        self.db
            .get_detailed_stats()
            .map_err(|e| format!("è·å–ç»Ÿè®¡å¤±è´¥: {}", e))
    }

    /// è·å–å¤±è´¥é»‘åå•æ•°é‡ï¼ˆå†…å­˜ + DBï¼‰
    pub fn get_failed_count(&self) -> Result<(usize, usize), String> {
        let memory_count = self.failed_index.read()
            .map(|idx| idx.len())
            .unwrap_or(0);
        let db_count = self.db
            .get_failed_count()
            .map_err(|e| format!("è·å–å¤±è´¥è®°å½•æ•°é‡å¤±è´¥: {}", e))?;
        Ok((memory_count, db_count))
    }

    /// æ¸…é™¤å¤±è´¥é»‘åå•ï¼ˆå†…å­˜ç´¢å¼• + æ•°æ®åº“è®°å½•ï¼‰
    pub fn clear_failed_index(&self) -> Result<usize, String> {
        // 1. æ¸…é™¤å†…å­˜ä¸­çš„å¤±è´¥ç´¢å¼•
        let memory_cleared = if let Ok(mut idx) = self.failed_index.write() {
            let count = idx.len();
            idx.clear();
            count
        } else {
            0
        };
        // 2. æ¸…é™¤æ•°æ®åº“ä¸­çš„å¤±è´¥è®°å½•
        let db_cleared = self.db
            .clear_all_failed_thumbnails()
            .map_err(|e| format!("æ¸…é™¤æ•°æ®åº“å¤±è´¥è®°å½•å¤±è´¥: {}", e))?;
        log_info!(
            "ğŸ§¹ å·²æ¸…é™¤å¤±è´¥é»‘åå•: å†…å­˜ {} æ¡, æ•°æ®åº“ {} æ¡",
            memory_cleared,
            db_cleared
        );
        Ok(memory_cleared + db_cleared)
    }

    /// æ¸…ç†æ— æ•ˆè·¯å¾„
    pub fn cleanup_invalid_paths(&self) -> Result<usize, String> {
        self.db
            .cleanup_invalid_paths()
            .map_err(|e| format!("æ¸…ç†å¤±è´¥: {}", e))
    }

    /// æ¸…ç†è¿‡æœŸæ¡ç›®
    pub fn cleanup_expired_entries(
        &self,
        days: i64,
        exclude_folders: bool,
    ) -> Result<usize, String> {
        self.db
            .cleanup_expired_entries(days, exclude_folders)
            .map_err(|e| format!("æ¸…ç†å¤±è´¥: {}", e))
    }

    /// æ¸…ç†æŒ‡å®šè·¯å¾„å‰ç¼€
    pub fn cleanup_by_path_prefix(&self, path_prefix: &str) -> Result<usize, String> {
        self.db
            .cleanup_by_path_prefix(path_prefix)
            .map_err(|e| format!("æ¸…ç†å¤±è´¥: {}", e))
    }

    /// æ‰§è¡Œæ•°æ®åº“å‹ç¼©
    pub fn vacuum_db(&self) -> Result<(), String> {
        self.db.vacuum().map_err(|e| format!("å‹ç¼©å¤±è´¥: {}", e))
    }

    /// åˆ é™¤å•ä¸ªç¼©ç•¥å›¾ç¼“å­˜
    pub fn remove_thumbnail(&self, path: &str) -> Result<(), String> {
        // ä»å†…å­˜ç¼“å­˜åˆ é™¤
        if let Ok(mut c) = self.memory_cache.write() {
            if let Some(blob) = c.pop(path) {
                self.memory_cache_bytes
                    .fetch_sub(blob.len(), Ordering::SeqCst);
            }
        }
        // ä»ä¿å­˜é˜Ÿåˆ—åˆ é™¤
        if let Ok(mut q) = self.save_queue.lock() {
            q.remove(path);
        }
        // ä»ç´¢å¼•åˆ é™¤
        if let Ok(mut i) = self.db_index.write() {
            i.remove(path);
        }
        if let Ok(mut i) = self.folder_db_index.write() {
            i.remove(path);
        }
        if let Ok(mut i) = self.failed_index.write() {
            i.remove(path);
        }
        // ä»æ•°æ®åº“åˆ é™¤
        self.db
            .delete_thumbnail(path)
            .map_err(|e| format!("åˆ é™¤å¤±è´¥: {}", e))
    }

    /// å¼ºåˆ¶é‡æ–°ç”Ÿæˆç¼©ç•¥å›¾
    pub fn regenerate_thumbnail(&self, app: &AppHandle, path: &str, current_dir: &str) {
        let Some(request_id) = self.request_deduplicator.try_acquire(path) else {
            log_debug!("ğŸ”„ è·³è¿‡é‡å¤é‡å»ºè¯·æ±‚: {}", path);
            return;
        };

        let file_type = detect_file_type(path);
        let task = GenerateTask {
            dedup_key: path.to_string(),
            dedup_request_id: request_id,
            path: path.to_string(),
            directory: current_dir.to_string(),
            request_epoch: self.request_epoch.load(Ordering::Acquire),
            lane: TaskLane::Visible,
            file_type,
            center_distance: 0,
            original_index: 0,
        };
        let dropped_tasks = queue::replace_path_with_task(&self.task_queue, path, task);
        for dropped in dropped_tasks {
            match dropped.lane {
                TaskLane::Visible => Self::dec_counter(&self.queued_visible),
                TaskLane::Prefetch => Self::dec_counter(&self.queued_prefetch),
                TaskLane::Background => Self::dec_counter(&self.queued_background),
            }
            self.request_deduplicator
                .release_with_id(&dropped.dedup_key, dropped.dedup_request_id);
        }
        self.queued_visible.fetch_add(1, Ordering::Relaxed);
        log_info!("ğŸ”„ å¼ºåˆ¶é‡æ–°ç”Ÿæˆç¼©ç•¥å›¾: {}", path);

        let _ = app;
    }

    /// æ£€æŸ¥å†…å­˜å‹åŠ›
    pub fn check_memory_pressure(&self, max_bytes: usize) {
        cache::check_memory_pressure(&self.memory_cache, &self.memory_cache_bytes, max_bytes);
    }

    /// æš‚åœè°ƒåº¦ï¼šworker ä¸æ¶ˆè´¹ä»»åŠ¡ï¼Œä½†ä¿æŒçº¿ç¨‹å­˜æ´»
    pub fn pause_scheduler(&self) {
        self.scheduler_paused.store(true, Ordering::Release);
    }

    /// æ¢å¤è°ƒåº¦å¹¶å”¤é†’ worker
    pub fn resume_scheduler(&self) {
        self.scheduler_paused.store(false, Ordering::Release);
        self.task_queue.1.notify_all();
    }
}

impl Drop for ThumbnailServiceV3 {
    fn drop(&mut self) {
        self.stop();
    }
}
